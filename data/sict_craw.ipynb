{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21876bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "import random \n",
    "from tqdm import tqdm \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import uuid\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d34236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [04:10<3:24:23, 250.27s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 101\u001b[0m\n\u001b[1;32m     99\u001b[0m src \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src:\n\u001b[0;32m--> 101\u001b[0m     saved_filename \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m saved_filename:\n\u001b[1;32m    103\u001b[0m         images_data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    104\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: src,\n\u001b[1;32m    105\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_filename\u001b[39m\u001b[38;5;124m\"\u001b[39m: saved_filename,\n\u001b[1;32m    106\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelative_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msaved_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m         })\n",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m, in \u001b[0;36mdownload_image\u001b[0;34m(img_url, save_folder)\u001b[0m\n\u001b[1;32m     17\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_folder, filename)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_content(\u001b[38;5;241m1024\u001b[39m):\n\u001b[1;32m     21\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(chunk)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filename \u001b[38;5;66;03m# Trả về tên file để lưu vào JSON\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/Agent/lib/python3.10/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/Agent/lib/python3.10/site-packages/urllib3/response.py:1253\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m (\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp)\n\u001b[1;32m   1250\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1251\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoder\u001b[38;5;241m.\u001b[39mhas_unconsumed_tail)\n\u001b[1;32m   1252\u001b[0m     ):\n\u001b[0;32m-> 1253\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1255\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1256\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/Agent/lib/python3.10/site-packages/urllib3/response.py:1087\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread\u001b[39m(\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1063\u001b[0m     amt: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1064\u001b[0m     decode_content: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1065\u001b[0m     cache_content: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1066\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbytes\u001b[39m:\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;124;03m    Similar to :meth:`http.client.HTTPResponse.read`, but with two additional\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m    parameters: ``decode_content`` and ``cache_content``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;124;03m        set.)\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1087\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decode_content \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1089\u001b[0m         decode_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode_content\n",
      "File \u001b[0;32m~/miniconda3/envs/Agent/lib/python3.10/site-packages/urllib3/response.py:606\u001b[0m, in \u001b[0;36mBaseHTTPResponse._init_decoder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;124;03mSet-up the _decoder attribute if necessary.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Note: content-encoding value should be case-insensitive, per RFC 7230\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;66;03m# Section 3.2\u001b[39;00m\n\u001b[0;32m--> 606\u001b[0m content_encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent-encoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCONTENT_DECODERS:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import uuid\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# --- HÀM HỖ TRỢ ---\n",
    "def download_image(img_url, save_folder):\n",
    "    \"\"\"Tải ảnh và trả về tên file local\"\"\"\n",
    "    try: \n",
    "        # Thêm User-Agent để tránh bị server chặn request ảnh\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        response = requests.get(img_url, headers=headers, stream=True, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            # Xử lý đuôi file\n",
    "            ext = img_url.split('.')[-1].split('?')[0]\n",
    "            if len(ext) > 4 or not ext: ext = \"jpg\"\n",
    "            \n",
    "            filename = f\"{uuid.uuid4()}.{ext}\"\n",
    "            file_path = os.path.join(save_folder, filename)\n",
    "            \n",
    "            with open(file_path, 'wb') as f:\n",
    "                for chunk in response.iter_content(1024):\n",
    "                    f.write(chunk)\n",
    "            return filename\n",
    "    except Exception as e:\n",
    "        # Chỉ in lỗi ngắn gọn để không làm rối màn hình\n",
    "        pass \n",
    "    return None\n",
    "\n",
    "# --- SETUP ---\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless=new') # Chạy ẩn\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Cấu hình đường dẫn\n",
    "root_dir = './sict_corpus/tintuc'\n",
    "images_dir = os.path.join(root_dir, 'images')\n",
    "os.makedirs(root_dir, exist_ok=True)\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "\n",
    "n_pages = 50\n",
    "news_id = 0\n",
    "\n",
    "# Sử dụng Explicit Wait\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "try:\n",
    "    for page_idx in tqdm(range(1, n_pages + 1), desc=\"Pages\"):\n",
    "        try:\n",
    "            # 1. Vào trang danh sách\n",
    "            main_url = f'https://sict.haui.edu.vn/vn/tin-tuc/{page_idx}'\n",
    "            driver.get(main_url)\n",
    "            \n",
    "            # Lấy danh sách link (Dùng wait để đảm bảo list đã load)\n",
    "            news_lst_xpath = '//section[contains(@class, \"irs-blog-field\")]//h2/a'\n",
    "            wait.until(EC.presence_of_element_located((By.XPATH, news_lst_xpath)))\n",
    "            \n",
    "            news_tags = driver.find_elements(By.XPATH, news_lst_xpath)\n",
    "            # Lưu lại list URL để tránh lỗi StaleElement khi chuyển trang\n",
    "            news_page_urls = [tag.get_attribute('href') for tag in news_tags]\n",
    "\n",
    "            # 2. Vào từng bài viết\n",
    "            for news_page_url in news_page_urls:\n",
    "                try:\n",
    "                    driver.get(news_page_url)\n",
    "                    \n",
    "                    # Định vị Main Content\n",
    "                    main_content_xpath = '//section[contains(@class, \"irs-blog-field\")]//div[@class=\"col-md-8\"]'\n",
    "                    try:\n",
    "                        main_content_tag = wait.until(EC.presence_of_element_located((By.XPATH, main_content_xpath)))\n",
    "                    except:\n",
    "                        # Nếu không load được content, bỏ qua bài này\n",
    "                        continue\n",
    "\n",
    "                    # --- TRÍCH XUẤT DỮ LIỆU ---\n",
    "                    \n",
    "                    # Title\n",
    "                    title = \"\"\n",
    "                    try:\n",
    "                        title = main_content_tag.find_element(By.XPATH, './/p[@class=\"pTitle\"]').text.strip()\n",
    "                    except: pass\n",
    "\n",
    "                    # Abstract\n",
    "                    abstract = \"\"\n",
    "                    try:\n",
    "                        abstract = main_content_tag.find_element(By.XPATH, './/p[@class=\"pHead\"]').text.strip()\n",
    "                    except: pass\n",
    "\n",
    "                    # Content & Images\n",
    "                    content_text = \"\"\n",
    "                    images_data = []\n",
    "                    \n",
    "                    try:\n",
    "                        # Lấy tất cả thẻ pBody\n",
    "                        paragraphs_tags = main_content_tag.find_elements(By.XPATH, './/p[@class=\"pBody\"]')\n",
    "                        text_parts = []\n",
    "                        \n",
    "                        # Logic: Bỏ thẻ cuối cùng ([:-1])\n",
    "                        target_paragraphs = paragraphs_tags[:-1] if paragraphs_tags else []\n",
    "\n",
    "                        for p_tag in target_paragraphs:\n",
    "                            # 1. Lấy Text\n",
    "                            text = p_tag.text.strip()\n",
    "                            if text:\n",
    "                                text_parts.append(text)\n",
    "                            \n",
    "                            # 2. Lấy Ảnh (QUAN TRỌNG: Chỉ tìm trong p_tag hiện tại)\n",
    "                            # Code cũ của bạn dùng main_content_tag ở đây gây lỗi lặp dữ liệu\n",
    "                            imgs_in_p = p_tag.find_elements(By.TAG_NAME, \"img\")\n",
    "                            \n",
    "                            for img in imgs_in_p:\n",
    "                                src = img.get_attribute('src')\n",
    "                                if src:\n",
    "                                    saved_filename = download_image(src, images_dir)\n",
    "                                    if saved_filename:\n",
    "                                        images_data.append({\n",
    "                                            \"original_url\": src,\n",
    "                                            \"local_filename\": saved_filename,\n",
    "                                            \"relative_path\": f\"images/{saved_filename}\"\n",
    "                                        })\n",
    "\n",
    "                        content_text = '\\n'.join(text_parts)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Lỗi parse body: {e}\")\n",
    "\n",
    "                    # --- LƯU JSON ---\n",
    "                    article_data = {\n",
    "                        \"id\": f\"sict_{news_id:05d}\",\n",
    "                        \"url\": news_page_url,\n",
    "                        \"title\": title,\n",
    "                        \"abstract\": abstract,\n",
    "                        \"content\": content_text,\n",
    "                        \"images\": images_data \n",
    "                    }\n",
    "\n",
    "                    news_filename = f\"new_sict_{news_id:05d}.json\"\n",
    "                    news_savepath = os.path.join(root_dir, news_filename)\n",
    "                    \n",
    "                    with open(news_savepath, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(article_data, f, ensure_ascii=False, indent=4)\n",
    "                    \n",
    "                    news_id += 1\n",
    "                    \n",
    "                    # Không cần driver.back() vì vòng lặp sẽ gọi driver.get() trang mới ngay\n",
    "\n",
    "                except Exception as inner_e:\n",
    "                    print(f\"Lỗi bài viết {news_page_url}: {inner_e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi trang danh sách {page_idx}: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Đảm bảo tắt trình duyệt khi xong hoặc gặp lỗi\n",
    "    driver.quit()\n",
    "    print(\"Hoàn tất crawl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab6897f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news_page_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe62a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
